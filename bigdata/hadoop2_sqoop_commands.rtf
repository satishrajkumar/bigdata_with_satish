{\rtf1\ansi\ansicpg1252\cocoartf2636
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww25100\viewh15140\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 ashish@ubuntu:~$ su -hduser\
\
Usage:\
 su [options] [-] [<user> [<argument>...]]\
\
Change the effective user ID and group ID to that of <user>.\
A mere - implies -l.  If <user> is not given, root is assumed.\
\
Options:\
 -m, -p, --preserve-environment      do not reset environment variables\
 -w, --whitelist-environment <list>  don't reset specified variables\
\
 -g, --group <group>             specify the primary group\
 -G, --supp-group <group>        specify a supplemental group\
\
 -, -l, --login                  make the shell a login shell\
 -c, --command <command>         pass a single command to the shell with -c\
 --session-command <command>     pass a single command to the shell with -c\
                                   and do not create a new session\
 -f, --fast                      pass -f to the shell (for csh or tcsh)\
 -s, --shell <shell>             run <shell> if /etc/shells allows it\
 -P, --pty                       create a new pseudo-terminal\
\
 -h, --help                      display this help\
 -V, --version                   display version\
\
For more details see su(1).\
ashish@ubuntu:~$ su - hduser\
Password: \
su: Authentication failure\
ashish@ubuntu:~$ su - hduser\
Password: \
hduser@ubuntu:~$ sqoop help\
Warning: /usr/local/sqoop/../hbase does not exist! HBase imports will fail.\
Please set $HBASE_HOME to the root of your HBase installation.\
Warning: /usr/local/sqoop/../hcatalog does not exist! HCatalog jobs will fail.\
Please set $HCAT_HOME to the root of your HCatalog installation.\
Warning: /usr/local/sqoop/../accumulo does not exist! Accumulo imports will fail.\
Please set $ACCUMULO_HOME to the root of your Accumulo installation.\
\\22/02/15 06:03:38 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7\
usage: sqoop COMMAND [ARGS]\
\
Available commands:\
  codegen            Generate code to interact with database records\
  create-hive-table  Import a table definition into Hive\
  eval               Evaluate a SQL statement and display the results\
  export             Export an HDFS directory to a database table\
  help               List available commands\
  import             Import a table from a database to HDFS\
  import-all-tables  Import tables from a database to HDFS\
  import-mainframe   Import datasets from a mainframe server to HDFS\
  job                Work with saved jobs\
  list-databases     List available databases on a server\
  list-tables        List available tables in a database\
  merge              Merge results of incremental imports\
  metastore          Run a standalone Sqoop metastore\
  version            Display version information\
\
See 'sqoop help COMMAND' for information on a specific command.\
hduser@ubuntu:~$ sqoop list-databases jdbc:mysql://localhost --username root -P\
Warning: /usr/local/sqoop/../hbase does not exist! HBase imports will fail.\
Please set $HBASE_HOME to the root of your HBase installation.\
Warning: /usr/local/sqoop/../hcatalog does not exist! HCatalog jobs will fail.\
Please set $HCAT_HOME to the root of your HCatalog installation.\
Warning: /usr/local/sqoop/../accumulo does not exist! Accumulo imports will fail.\
Please set $ACCUMULO_HOME to the root of your Accumulo installation.\
22/02/15 06:05:16 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7\
22/02/15 06:05:16 ERROR tool.BaseSqoopTool: Error parsing arguments for list-databases:\
22/02/15 06:05:16 ERROR tool.BaseSqoopTool: Unrecognized argument: jdbc:mysql://localhost\
22/02/15 06:05:16 ERROR tool.BaseSqoopTool: Unrecognized argument: --username\
22/02/15 06:05:16 ERROR tool.BaseSqoopTool: Unrecognized argument: root\
22/02/15 06:05:16 ERROR tool.BaseSqoopTool: Unrecognized argument: -P\
\
Try --help for usage instructions.\
hduser@ubuntu:~$ sqoop list-databases --connect jdbc:mysql://localhost --username root -P\
Warning: /usr/local/sqoop/../hbase does not exist! HBase imports will fail.\
Please set $HBASE_HOME to the root of your HBase installation.\
Warning: /usr/local/sqoop/../hcatalog does not exist! HCatalog jobs will fail.\
Please set $HCAT_HOME to the root of your HCatalog installation.\
Warning: /usr/local/sqoop/../accumulo does not exist! Accumulo imports will fail.\
Please set $ACCUMULO_HOME to the root of your Accumulo installation.\
22/02/15 06:05:51 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7\
Enter password: \
22/02/15 06:06:10 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.\
Tue Feb 15 06:06:10 PST 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\
mysql\
information_schema\
performance_schema\
sys\
training\
hduser@ubuntu:~$ sqoop list-tables --connect jdbc:mysql://localhost/training --username root -P\
Warning: /usr/local/sqoop/../hbase does not exist! HBase imports will fail.\
Please set $HBASE_HOME to the root of your HBase installation.\
Warning: /usr/local/sqoop/../hcatalog does not exist! HCatalog jobs will fail.\
Please set $HCAT_HOME to the root of your HCatalog installation.\
Warning: /usr/local/sqoop/../accumulo does not exist! Accumulo imports will fail.\
Please set $ACCUMULO_HOME to the root of your Accumulo installation.\
22/02/15 06:07:35 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7\
Enter password: \
22/02/15 06:07:43 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.\
Tue Feb 15 06:07:44 PST 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\
emp\
employee\
student\
hduser@ubuntu:~$ sqoop list-tables --help\
Warning: /usr/local/sqoop/../hbase does not exist! HBase imports will fail.\
Please set $HBASE_HOME to the root of your HBase installation.\
Warning: /usr/local/sqoop/../hcatalog does not exist! HCatalog jobs will fail.\
Please set $HCAT_HOME to the root of your HCatalog installation.\
Warning: /usr/local/sqoop/../accumulo does not exist! Accumulo imports will fail.\
Please set $ACCUMULO_HOME to the root of your Accumulo installation.\
22/02/15 06:08:26 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7\
usage: sqoop list-tables [GENERIC-ARGS] [TOOL-ARGS]\
\
Common arguments:\
   --connect <jdbc-uri>                                       Specify JDBC\
                                                              connect\
                                                              string\
   --connection-manager <class-name>                          Specify\
                                                              connection\
                                                              manager\
                                                              class name\
   --connection-param-file <properties-file>                  Specify\
                                                              connection\
                                                              parameters\
                                                              file\
   --driver <class-name>                                      Manually\
                                                              specify JDBC\
                                                              driver class\
                                                              to use\
   --hadoop-home <hdir>                                       Override\
                                                              $HADOOP_MAPR\
                                                              ED_HOME_ARG\
   --hadoop-mapred-home <dir>                                 Override\
                                                              $HADOOP_MAPR\
                                                              ED_HOME_ARG\
   --help                                                     Print usage\
                                                              instructions\
   --metadata-transaction-isolation-level <isolationlevel>    Defines the\
                                                              transaction\
                                                              isolation\
                                                              level for\
                                                              metadata\
                                                              queries. For\
                                                              more details\
                                                              check\
                                                              java.sql.Con\
                                                              nection\
                                                              javadoc or\
                                                              the JDBC\
                                                              specificaito\
                                                              n\
   --oracle-escaping-disabled <boolean>                       Disable the\
                                                              escaping\
                                                              mechanism of\
                                                              the\
                                                              Oracle/OraOo\
                                                              p connection\
                                                              managers\
-P                                                            Read\
                                                              password\
                                                              from console\
   --password <password>                                      Set\
                                                              authenticati\
                                                              on password\
   --password-alias <password-alias>                          Credential\
                                                              provider\
                                                              password\
                                                              alias\
   --password-file <password-file>                            Set\
                                                              authenticati\
                                                              on password\
                                                              file path\
   --relaxed-isolation                                        Use\
                                                              read-uncommi\
                                                              tted\
                                                              isolation\
                                                              for imports\
   --skip-dist-cache                                          Skip copying\
                                                              jars to\
                                                              distributed\
                                                              cache\
   --temporary-rootdir <rootdir>                              Defines the\
                                                              temporary\
                                                              root\
                                                              directory\
                                                              for the\
                                                              import\
   --throw-on-error                                           Rethrow a\
                                                              RuntimeExcep\
                                                              tion on\
                                                              error\
                                                              occurred\
                                                              during the\
                                                              job\
   --username <username>                                      Set\
                                                              authenticati\
                                                              on username\
   --verbose                                                  Print more\
                                                              information\
                                                              while\
                                                              working\
\
Generic Hadoop command-line arguments:\
(must preceed any tool-specific arguments)\
Generic options supported are:\
-conf <configuration file>        specify an application configuration file\
-D <property=value>               define a value for a given property\
-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.\
-jt <local|resourcemanager:port>  specify a ResourceManager\
-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster\
-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath\
-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines\
\
The general command line syntax is:\
command [genericOptions] [commandOptions]\
\
\
hduser@ubuntu:~$ \
hduser@ubuntu:~$ select * from emp;\
-bash: syntax error near unexpected token `from'\
hduser@ubuntu:~$ hadoop fs -ls /\
22/02/15 06:11:57 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
Found 2 items\
drwx------   - hduser supergroup          0 2022-02-09 07:12 /tmp\
drwxr-xr-x   - hduser supergroup          0 2022-02-09 07:12 /user\
hduser@ubuntu:~$ hadoop fs -ls /user\
22/02/15 06:12:19 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
Found 1 items\
drwxr-xr-x   - hduser supergroup          0 2022-02-11 07:00 /user/hduser\
hduser@ubuntu:~$ hadoop fs -ls /user/hduser\
22/02/15 06:12:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
Found 1 items\
drwxr-xr-x   - hduser supergroup          0 2022-02-10 06:26 /user/hduser/QuasiMonteCarlo_1644503189123_1579960533\
hduser@ubuntu:~$ sqoop import --connect jdbc:mysql://localhost/training --table emp --username root -P\
Warning: /usr/local/sqoop/../hbase does not exist! HBase imports will fail.\
Please set $HBASE_HOME to the root of your HBase installation.\
Warning: /usr/local/sqoop/../hcatalog does not exist! HCatalog jobs will fail.\
Please set $HCAT_HOME to the root of your HCatalog installation.\
Warning: /usr/local/sqoop/../accumulo does not exist! Accumulo imports will fail.\
Please set $ACCUMULO_HOME to the root of your Accumulo installation.\
22/02/15 06:16:18 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7\
Enter password: \
22/02/15 06:16:26 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.\
22/02/15 06:16:26 INFO tool.CodeGenTool: Beginning code generation\
Tue Feb 15 06:16:26 PST 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\
22/02/15 06:16:27 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `emp` AS t LIMIT 1\
22/02/15 06:16:27 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `emp` AS t LIMIT 1\
22/02/15 06:16:27 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/local/hadoop\
Note: /tmp/sqoop-hduser/compile/c1064f5cbb980adce4d5b4d3cd0d30df/emp.java uses or overrides a deprecated API.\
Note: Recompile with -Xlint:deprecation for details.\
22/02/15 06:16:31 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-hduser/compile/c1064f5cbb980adce4d5b4d3cd0d30df/emp.jar\
22/02/15 06:16:31 WARN manager.MySQLManager: It looks like you are importing from mysql.\
22/02/15 06:16:31 WARN manager.MySQLManager: This transfer can be faster! Use the --direct\
22/02/15 06:16:31 WARN manager.MySQLManager: option to exercise a MySQL-specific fast path.\
22/02/15 06:16:31 INFO manager.MySQLManager: Setting zero DATETIME behavior to convertToNull (mysql)\
22/02/15 06:16:31 INFO mapreduce.ImportJobBase: Beginning import of emp\
22/02/15 06:16:31 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
22/02/15 06:16:31 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\
22/02/15 06:16:33 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\
22/02/15 06:16:33 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\
Tue Feb 15 06:16:37 PST 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\
22/02/15 06:16:37 INFO db.DBInputFormat: Using read commited transaction isolation\
22/02/15 06:16:37 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(`id`), MAX(`id`) FROM `emp`\
22/02/15 06:16:37 INFO db.IntegerSplitter: Split size: 125; Num splits: 4 from: 100 to: 600\
22/02/15 06:16:37 INFO mapreduce.JobSubmitter: number of splits:4\
22/02/15 06:16:37 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled\
22/02/15 06:16:37 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1644931147527_0001\
22/02/15 06:16:39 INFO impl.YarnClientImpl: Submitted application application_1644931147527_0001\
22/02/15 06:16:39 INFO mapreduce.Job: The url to track the job: http://ubuntu:8088/proxy/application_1644931147527_0001/\
22/02/15 06:16:39 INFO mapreduce.Job: Running job: job_1644931147527_0001\
22/02/15 06:16:54 INFO mapreduce.Job: Job job_1644931147527_0001 running in uber mode : false\
22/02/15 06:16:54 INFO mapreduce.Job:  map 0% reduce 0%\
22/02/15 06:17:16 INFO mapreduce.Job:  map 50% reduce 0%\
22/02/15 06:17:18 INFO mapreduce.Job:  map 100% reduce 0%\
22/02/15 06:17:19 INFO mapreduce.Job: Job job_1644931147527_0001 completed successfully\
22/02/15 06:17:19 INFO mapreduce.Job: Counters: 31\
	File System Counters\
		FILE: Number of bytes read=0\
		FILE: Number of bytes written=827888\
		FILE: Number of read operations=0\
		FILE: Number of large read operations=0\
		FILE: Number of write operations=0\
		HDFS: Number of bytes read=409\
		HDFS: Number of bytes written=99\
		HDFS: Number of read operations=16\
		HDFS: Number of large read operations=0\
		HDFS: Number of write operations=8\
	Job Counters \
		Killed map tasks=1\
		Launched map tasks=4\
		Other local map tasks=4\
		Total time spent by all maps in occupied slots (ms)=76337\
		Total time spent by all reduces in occupied slots (ms)=0\
		Total time spent by all map tasks (ms)=76337\
		Total vcore-milliseconds taken by all map tasks=76337\
		Total megabyte-milliseconds taken by all map tasks=78169088\
	Map-Reduce Framework\
		Map input records=6\
		Map output records=6\
		Input split bytes=409\
		Spilled Records=0\
		Failed Shuffles=0\
		Merged Map outputs=0\
		GC time elapsed (ms)=1775\
		CPU time spent (ms)=9620\
		Physical memory (bytes) snapshot=790384640\
		Virtual memory (bytes) snapshot=7614345216\
		Total committed heap usage (bytes)=389545984\
	File Input Format Counters \
		Bytes Read=0\
	File Output Format Counters \
		Bytes Written=99\
22/02/15 06:17:19 INFO mapreduce.ImportJobBase: Transferred 99 bytes in 46.0687 seconds (2.149 bytes/sec)\
22/02/15 06:17:19 INFO mapreduce.ImportJobBase: Retrieved 6 records.\
hduser@ubuntu:~$ hadoop fs -ls /\
22/02/15 06:26:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
Found 2 items\
drwx------   - hduser supergroup          0 2022-02-09 07:12 /tmp\
drwxr-xr-x   - hduser supergroup          0 2022-02-09 07:12 /user\
hduser@ubuntu:~$ cd /user/hduser\
-bash: cd: /user/hduser: No such file or directory\
hduser@ubuntu:~$ hadoop fs -ls /user\
22/02/15 06:27:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
Found 1 items\
drwxr-xr-x   - hduser supergroup          0 2022-02-15 06:16 /user/hduser\
hduser@ubuntu:~$ hadoop fs -ls /user/hduser\
22/02/15 06:27:40 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
Found 2 items\
drwxr-xr-x   - hduser supergroup          0 2022-02-10 06:26 /user/hduser/QuasiMonteCarlo_1644503189123_1579960533\
drwxr-xr-x   - hduser supergroup          0 2022-02-15 06:17 /user/hduser/emp\
hduser@ubuntu:~$ hadoop fs -ls /user/hduser/emp\
22/02/15 06:28:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
Found 5 items\
-rw-r--r--   1 hduser supergroup          0 2022-02-15 06:17 /user/hduser/emp/_SUCCESS\
-rw-r--r--   1 hduser supergroup         31 2022-02-15 06:17 /user/hduser/emp/part-m-00000\
-rw-r--r--   1 hduser supergroup         17 2022-02-15 06:17 /user/hduser/emp/part-m-00001\
-rw-r--r--   1 hduser supergroup         17 2022-02-15 06:17 /user/hduser/emp/part-m-00002\
-rw-r--r--   1 hduser supergroup         34 2022-02-15 06:17 /user/hduser/emp/part-m-00003\
hduser@ubuntu:~$ hadoop -cat /user/hduser/emp/part-m-00000\
Error: No command named `-cat' was found. Perhaps you meant `hadoop cat'\
hduser@ubuntu:~$ hadoop fs -cat /user/hduser/emp/part-m-0000022/02/15 06:34:04 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
100,ram,55000\
200,sachin,65000\
hduser@ubuntu:~$ hadoop fs -cat /user/hduser/emp/part-m-00001\
22/02/15 06:35:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
300,sehvag,70000\
hduser@ubuntu:~$ hadoop fs -cat /user/hduser/emp/part-m-00002\
22/02/15 06:35:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
400,dravid,75000\
hduser@ubuntu:~$ hadoop fs -cat /user/hduser/emp/part-m-00003\
22/02/15 06:35:20 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
500,saurav,76000\
600,yuvraj,77000\
hduser@ubuntu:~$ sqoop import --connect jdbc:mysql://localhost/training --table emp --target-dir /sqoopjob1 --username root -P -m 1\
Warning: /usr/local/sqoop/../hbase does not exist! HBase imports will fail.\
Please set $HBASE_HOME to the root of your HBase installation.\
Warning: /usr/local/sqoop/../hcatalog does not exist! HCatalog jobs will fail.\
Please set $HCAT_HOME to the root of your HCatalog installation.\
Warning: /usr/local/sqoop/../accumulo does not exist! Accumulo imports will fail.\
Please set $ACCUMULO_HOME to the root of your Accumulo installation.\
22/02/15 07:11:41 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7\
Enter password: \
22/02/15 07:11:50 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.\
22/02/15 07:11:50 INFO tool.CodeGenTool: Beginning code generation\
Tue Feb 15 07:11:50 PST 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\
22/02/15 07:11:51 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `emp` AS t LIMIT 1\
22/02/15 07:11:51 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `emp` AS t LIMIT 1\
22/02/15 07:11:51 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/local/hadoop\
Note: /tmp/sqoop-hduser/compile/b7b247709fbbccdf2c67198bb3dc47be/emp.java uses or overrides a deprecated API.\
Note: Recompile with -Xlint:deprecation for details.\
22/02/15 07:11:56 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-hduser/compile/b7b247709fbbccdf2c67198bb3dc47be/emp.jar\
22/02/15 07:11:56 WARN manager.MySQLManager: It looks like you are importing from mysql.\
22/02/15 07:11:56 WARN manager.MySQLManager: This transfer can be faster! Use the --direct\
22/02/15 07:11:56 WARN manager.MySQLManager: option to exercise a MySQL-specific fast path.\
22/02/15 07:11:56 INFO manager.MySQLManager: Setting zero DATETIME behavior to convertToNull (mysql)\
22/02/15 07:11:56 INFO mapreduce.ImportJobBase: Beginning import of emp\
22/02/15 07:11:56 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
22/02/15 07:11:56 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\
22/02/15 07:11:57 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\
22/02/15 07:11:58 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\
Tue Feb 15 07:12:01 PST 2022 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\
22/02/15 07:12:02 INFO db.DBInputFormat: Using read commited transaction isolation\
22/02/15 07:12:02 INFO mapreduce.JobSubmitter: number of splits:1\
22/02/15 07:12:02 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled\
22/02/15 07:12:02 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1644931147527_0002\
22/02/15 07:12:03 INFO impl.YarnClientImpl: Submitted application application_1644931147527_0002\
22/02/15 07:12:03 INFO mapreduce.Job: The url to track the job: http://ubuntu:8088/proxy/application_1644931147527_0002/\
22/02/15 07:12:03 INFO mapreduce.Job: Running job: job_1644931147527_0002\
22/02/15 07:12:24 INFO mapreduce.Job: Job job_1644931147527_0002 running in uber mode : false\
22/02/15 07:12:24 INFO mapreduce.Job:  map 0% reduce 0%\
22/02/15 07:12:38 INFO mapreduce.Job:  map 100% reduce 0%\
22/02/15 07:12:39 INFO mapreduce.Job: Job job_1644931147527_0002 completed successfully\
22/02/15 07:12:40 INFO mapreduce.Job: Counters: 30\
	File System Counters\
		FILE: Number of bytes read=0\
		FILE: Number of bytes written=206966\
		FILE: Number of read operations=0\
		FILE: Number of large read operations=0\
		FILE: Number of write operations=0\
		HDFS: Number of bytes read=87\
		HDFS: Number of bytes written=99\
		HDFS: Number of read operations=4\
		HDFS: Number of large read operations=0\
		HDFS: Number of write operations=2\
	Job Counters \
		Launched map tasks=1\
		Other local map tasks=1\
		Total time spent by all maps in occupied slots (ms)=10367\
		Total time spent by all reduces in occupied slots (ms)=0\
		Total time spent by all map tasks (ms)=10367\
		Total vcore-milliseconds taken by all map tasks=10367\
		Total megabyte-milliseconds taken by all map tasks=10615808\
	Map-Reduce Framework\
		Map input records=6\
		Map output records=6\
		Input split bytes=87\
		Spilled Records=0\
		Failed Shuffles=0\
		Merged Map outputs=0\
		GC time elapsed (ms)=257\
		CPU time spent (ms)=2250\
		Physical memory (bytes) snapshot=209080320\
		Virtual memory (bytes) snapshot=1911689216\
		Total committed heap usage (bytes)=98566144\
	File Input Format Counters \
		Bytes Read=0\
	File Output Format Counters \
		Bytes Written=99\
22/02/15 07:12:40 INFO mapreduce.ImportJobBase: Transferred 99 bytes in 42.7172 seconds (2.3176 bytes/sec)\
22/02/15 07:12:40 INFO mapreduce.ImportJobBase: Retrieved 6 records.\
hduser@ubuntu:~$ hdfs dfs -ls /sqoopjob1\
22/02/15 07:12:56 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
Found 2 items\
-rw-r--r--   1 hduser supergroup          0 2022-02-15 07:12 /sqoopjob1/_SUCCESS\
-rw-r--r--   1 hduser supergroup         99 2022-02-15 07:12 /sqoopjob1/part-m-00000\
hduser@ubuntu:~$ hdfs dfs -cat sqoopjob1/part-m-00000\
22/02/15 07:13:17 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
cat: `sqoopjob1/part-m-00000': No such file or directory\
hduser@ubuntu:~$ hdfs dfs -cat /sqoopjob1/part-m-00000\
22/02/15 07:13:27 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
100,ram,55000\
200,sachin,65000\
300,sehvag,70000\
400,dravid,75000\
500,saurav,76000\
600,yuvraj,77000\
hduser@ubuntu:~$ \
}