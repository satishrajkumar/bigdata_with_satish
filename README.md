<!-- Hero Banner Image: Top of the README -->
<img src="assets/hero_banner.png" alt="Hero Banner" width="800">
---

## ğŸ‘¨â€ğŸ’» About Me
<a id="about"></a>
Iâ€™m a Results-driven Data Engineer with over 5 years of experience designing and optimizing ETL/ELT pipelines, handling large-scale structured and semi-structured data, and implementing cloud-native solutions.  

**Specialties include:**
- Building robust data pipelines using Python, PySpark, SQL
- Working across modern cloud stacks: AWS Glue, Lambda, S3, EC2, GCP, BigQuery  
- Developing scalable solutions on Databricks and Snowflake 
- Orchestrating workflows with Apache Airflow
- Driving data quality, performance tuning, and cost-optimized design  

> Proven track record: Up to **30% reduction in ETL runtime** and highly reliable pipelines (**99.9% uptime**).

---

## ğŸ“ Education
- B.E., PDA College of Engineering (2014â€“2018)

---

# Work Experience
<a id="experience"></a>

## **Publicis Sapient, Hyderabad, India**  
**Sr. Data Engineer (2024-Present)**

### Projects
### 1.ğŸ§ Podcast Listener Analytics â€“ Audience Platform Data Lake
**Tech Stack:** PySpark, Databricks, AWS S3, AWS Lambda  


The Audience platform was built as a single source of truth data lake for all business units. It centralizes audience and podcast listener data and enables enterprise-wide reporting, advanced analytics, and data science model training.

- Built scalable ingestion and transformation pipelines  
- Designed multi-layer architecture: Landing â†’ Silver â†’ Analytical
- Implemented listener mapping algorithms across multiple sources  
- Orchestrated ETL workflows using Databricks Workflows  
- Optimized query performance with PySpark and SQL tuning


### 2.ğŸ”„ Redshift to Salesforce Migration
**Tech Stack:** AWS Glue, AWS S3, Python Bulk API v2, PySpark  

- Migrated 1TB member records across Salesforce objects  
- Used AWS Glue workflows for scalable ETL  
- Implemented bulk insert/upsert logic via Python Bulk API v2  
- Achieved <1% error rate in production (Certificate of Excellence)  

---

## **Happiest Minds Technologies Ltd , Bangalore, India**  
**Data Engineer (2022-2024)**

### Projects
	
	DataOps & MLOps Platform â€“ Transport Sector 
	â€¢ Built and operated DataOps frameworks across Dev, UAT, Pre-Prod, and Prod, enabling data quality, monitoring, and 
	reliable ML deployments for multiple transport-sector applications. 
	â€¢ Developed and automated ETL pipelines using AWS Lambda â†’ AWS Glue (PySpark) â†’ Amazon Redshift/S3, with 
	configurable data quality frameworks and proactive production issue resolution, ensuring stable, SLA-compliant pipelines. 
	â€¢ Owned end-to-end ETL delivery for Parts Back Order Analysis, ingesting dealership and vendor data via S3/Athena, 
	transforming through Glue, and serving curated datasets from Redshift to support inventory planning and shortage analysis 
	across all environments. 
	â€¢ Supported ML model deployments in collaboration with data scientists by operationalizing models through AWS services, 
	enabling smooth productionization, monitoring, and post-deployment support. 
	â€¢ Administered Amazon Redshift and built AWS cloud billing dashboards in Power BI using CloudWatch metrics and alerts, 
	improving cost visibility, usage tracking, and operational control. 
	 
	Parts Back Order Analysis (Transport Sector (MSIL)) 
	â€¢ Built a data analytics platform to analyze dealership Parts Back Orders, enabling the PAP team to identify root causes of 
	inventory shortages and support proactive inventory planning. 
	â€¢ Designed and implemented ETL pipelines using Amazon S3 â†’ AWS Glue (PySpark) â†’ Amazon Redshift, with Amazon 
	Athena for ad-hoc analysis and validation, delivering analytics-ready datasets for reporting. 
	â€¢ Developed backend APIs using AWS API Gateway â†’ AWS Lambda â†’ Amazon Redshift, exposing curated data to 
	dashboards and applications, enabling faster insights and data-driven decision-making. 
	â€¢ Tech Stack & Tools used: 
	â€¢ S3, Glue, Lambda, Redshift, Athena, API Gateway, Step Functions, Secrets Manager, CloudWatch,PySpark, SQL, ETL 
	Pipelines, Data Warehousing, RDS ,GitHub, Jira 

---

## **Webtouch Software Development Pvt Ltd**  
**Role:** Data Engineer (2019-2021)

### Projects
	
	Sentiment Analysis Using Automated ML | Banking Sector 
	â€¢ Built a sentiment analysis pipeline to process customer text data (reviews, posts, feedback) using S3 â†’ AWS Glue (ETL) â†’ 
	ML-ready datasets, enabling customer segmentation, service prioritization, and product improvement insights. 
	â€¢ Performed data cleaning, filtering, and transformations to deliver high-quality datasets for automated machine learning 
	models, improving model reliability and analytical accuracy. 
	â€¢ Developed and monitored AWS Lambdaâ€“triggered Glue jobs, provided production support, and supported ML model 
	deployment using AWS services, ensuring stable and scalable sentiment analytics pipelines. 
	 
	Enhancing E-Commerce Data Platform | Health Sector 
	â€¢ Built event-driven ETL pipelines (S3 â†’ Lambda â†’ AWS Glue â†’ Snowflake) to process product, inventory, pricing, and 
	order feeds, enabling near real-time ingestion and scalable analytics. 
	â€¢ Implemented data validation, quality checks, and business rules, loading curated datasets into Snowflake schemas and 
	routing invalid/dependent records to reprocessing layers, improving data reliability. 
	â€¢ Developed Glue extract jobs (Snowflake â†’ S3 CSV) to deliver SAP-ready datasets and sales analytics (top products, 
	revenue trends), supporting data-driven business decisions and frontend reporting 
	â€¢  Tech Stack & Tools used: 
	â€¢ Python, PySpark, SQL, AWS S3, Lambda, Glue, EMR, EC2, Step Functions, CloudWatch, Snowflake.

---

## ğŸŒ GitHub Pages Portfolio Website
<a id="portfolio"></a>

ğŸ”— [https://satishrajkumar.github.io](https://satishrajkumar.github.io) 

---

## ğŸ“« Contact Me
<a id="contact"></a>
- ğŸ“§ **Email**: [satishrajkumar001@gmail.com](mailto:satishrajkumar001@gmail.com)  
- ğŸ”— **LinkedIn**: [linkedin.com/in/yourprofile](https://www.linkedin.com/in/satish-r-1458b1311/)

---

## ğŸ… Achievements

- Teamwork,Excellence  â€“ Happiest Minds Technologies ltd
- Successfully migrated 17M+ records with <1% error  
- Reduced ETL runtime by 30% across multiple pipelines  

---

## ğŸ¨ Hobbies & Interests

- Data visualization & dashboards  
- Open-source contributions  
- Reading technical blogs & research papers  
- Playing chess  

---
## ğŸ› ï¸ Skills & Tools
<a id="skills"></a>

| Category              | Tools & Technologies                               |
|-----------------------|-----------------------------------------------------|
| Programming           | Python, SQL, PySpark, Pandas                        |
| Cloud                 | AWS (Glue, S3, Lambda, EC2), Snowflake              |
| Big Data              | Databricks, Hadoop, Spark                           |
| Workflow Orchestration| Apache Airflow, AWS Glue Workflows                 |
| Visualization         | Power BI                                            |
| Databases             | Redshift, RDS, SQL Server                          |
| Version Control       | Git, GitHub, JIRA                                   |


## ğŸ“œ License

This repository is open-source and available for educational and portfolio purposes. Please attribute if referencing or reusing code.

---

## ğŸ™ Acknowledgments

Thanks to mentors, peers, and teams who shaped my professional journey and these projects.

