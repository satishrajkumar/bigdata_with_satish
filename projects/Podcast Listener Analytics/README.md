# ğŸ§ Podcast Listener Analytics â€“ Entertainment Domain

## ğŸ“˜ Overview

This project implements a scalable, cloud-based data pipeline that processes and analyzes podcast listener data. It unifies anonymous user activity with registered user profiles and builds a consolidated individual view that helps generate actionable insights for personalization and targeted advertising.

---

## ğŸ’¼ Business Use Case

Podcast platforms capture listener data from both **registered** and **anonymous users**. To enable effective marketing and audience understanding, this project:

- Maps anonymous users to known individuals using third-party identity services.
- Creates a single, enriched profile per user or household.
- Enables downstream teams to analyze:
  - Content consumption patterns
  - Regional trends
  - Age-group-wise interests
  - Optimal ad placements

This data powers:

- ğŸ¯ Audience segmentation and targeting  
- ğŸ“ˆ Revenue optimization through intelligent ad placement  
- ğŸ“Š Content strategy and recommendation engines  

---

ğŸ“ˆ Impact & Results
- 360Â° Audience View: Enabled 100% mapping of anonymous playback events to unique household/user profiles.
- Smarter Ads: Provided data for regional and age-group trend analysis, improving ad placement accuracy by an estimated 25%.
- Clean Data: Automated validation reduced manual data cleansing time by 40%.

--
## ğŸ§‘â€ğŸ’» Tech Stack

| Component         | Technology Used                        |
|------------------|----------------------------------------|
| Cloud Storage     | AWS S3                                 |
| Processing Engine | PySpark on Databricks (Delta Lake)     |
| Orchestration     | Databricks Workflows                   |
| Validation        | Python (Regex-based field validation)  |
| Identity Mapping  | Third-party Identity Resolution API    |

---

## ğŸ—ƒï¸ Data Sources

| Table Name         | Type        | Description                                      |
|--------------------|-------------|--------------------------------------------------|
| `fact_listening_a` | Fact Table  | Anonymous listener activity from source A        |
| `fact_listening_b` | Fact Table  | Anonymous listener activity from source B        |
| `fact_listening_c` | Fact Table  | Anonymous listener activity from source C        |
| `dim_user_profile` | Dimension   | Registered user data with verified identities    |

> ğŸ” Note: These table names are generic placeholders to protect actual schema details.

---

## ğŸ—ï¸ Data Architecture


### ğŸ”¹ Landing Zone
- Raw ingestion from AWS S3 to Delta tables using Databricks Autoloader.

### ğŸ”¹ Silver Layer (Validation & Cleansing)
Performed field-level data quality checks:
- âœ… Email format validation â†’ `is_email_valid`
- âœ… Phone number structure check â†’ `is_phone_valid`
- âœ… IP address pattern verification â†’ `is_ip_valid`
- âœ… Mobile Advertising ID (MAID) validation â†’ `is_maid_valid`

### ğŸ”¹ Identity Enrichment
- Encrypted user signals sent to a **third-party identity resolution service**
- Received back household or individual-level unified identifiers
- Mapped multiple anonymous records to likely registered users

### ğŸ”¹ Golden Layer (`individual_profile`)
- Merged validated anonymous data with registered profiles
- Generated unique UUIDs per individual
- Maintained a **consolidated user identity** table for downstream analytics

---

## ğŸ” Orchestration

All pipelines are orchestrated using **Databricks Workflows**:
- End-to-end ETL automation
- Job dependency chaining
- Retry logic and email alerts
- Minimal manual intervention

---

## ğŸ“Š Final Output Table: `individual_profile`

This table is consumed by downstream teams to:
- Analyze audience behavior by age, region, platform, and device
- Support machine learning models for recommendation and churn prediction
- Place personalized advertisements based on listener profiles

---

## âœ… Key Contributions

- Designed and implemented **multi-layer architecture** (Landing â†’ Silver â†’ Gold)
- Built reusable **PySpark transformation pipelines**
- Integrated **external identity provider** for user mapping
- Created **validation logic** for critical fields (email, phone, IP, MAID)
- Developed a unified `individual_profile` table for analytics

---



