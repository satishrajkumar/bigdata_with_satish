# ðŸ”„ Redshift to Salesforce Migration

**Tech Stack**: AWS Glue â€¢ AWS S3 â€¢ PySpark â€¢ Python â€¢ Salesforce Bulk API v2

## ðŸ“Œ Overview

This project showcases a robust end-to-end **data migration pipeline** designed to migrate over **17 million member records** from data files in **Amazon S3** into **Salesforce** using a combination of **AWS Glue**, **PySpark**, and the **Salesforce Bulk API v2**.

The pipeline is part of a larger portfolio of Data Engineering solutions and follows a modular, config-driven architecture to allow easy scaling and adaptability.

---

## ðŸš€ Project Highlights

- âœ… Migrated **17M+ records** across 6 critical Salesforce objects with <1% error rate.
- ðŸ” Designed **initial load** and **delta load** pipelines (2â€“3 million records per delta).
- ðŸ§© Developed using **PySpark** for transformations and column mapping.
- â˜ï¸ Used **AWS Glue workflows** to orchestrate end-to-end processing.
- ðŸ“¥ **Extracted** source files from **AWS S3**, applied business logic, and loaded transformed data back to S3 before ingestion.
- ðŸ“¤ Used **Python with Bulk API v2** for high-volume Salesforce ingestion (Insert & Upsert support).
- ðŸ† Received a **Certificate of Excellence** from the client for delivery and performance.

---

## ðŸ› ï¸ Architecture

```text
        +-------------+
        |  AWS S3     |  <- Raw Data Files (CSV)
        +-------------+
               |
               v
        +------------------+
        |  AWS Glue (ETL)  |  <- PySpark Jobs
        +------------------+
               |
               v
        +----------------------+
        |  AWS S3 (Processed)  |  <- Transformed Output
        +----------------------+
               |
               v
        +---------------------------+
        |  Python Bulk API v2      |  <- Salesforce Ingestion
        +---------------------------+
